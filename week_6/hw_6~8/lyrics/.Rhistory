idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
help('idfCal')
idf_tag <- apply(as.matrix(TDM_tag[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
# 讀檔
setwd("D:/107-1RSampleCode/week_6&7&8/TextMining_EDA")
dta <- read.csv(file = "data/tang300/tang300_utf-8.csv", fileEncoding = "UTF-8",
stringsAsFactors=F)
#轉成類別型態
dta[,'author'] = as.factor(dta[,'author'])
dta[,'style'] = as.factor(dta[,'style'])
# LISTS
author_list = list(unique(dta$author))[[1]]
tag_list = c('寫景', '思鄉', '抒情', '送別', '友情', '思念', '樂府', '女子', '寫人', '邊塞', '懷古', '生活', '山水',
'戰爭', '秋天', '哲理', '孤獨', '月亮', '愛情', '懷人', '宮怨', '詠史懷古', '離別', '閨怨', '冬天', '抒懷', '詠物')
# FUNCTIONS
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
help(segment) #斷詞function
count_token = function(d)
{
as.data.frame(table(d))
}
idfCal <- function(word_doc, n)
{
log2( n / nnzero(word_doc) )
}
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
View(tfidf)
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf))
head(freq,10)
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf))
str(tfidf)
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf[,2:]))
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf[,2:78]))
head(freq,10)
doc.tfidf_tag
#1. 建立文本資料結構與基本文字清洗
d.corpus_tag <- Corpus(DirSource("./data/tang300/by_tag", encoding = "UTF-8"))
d.corpus_tag <- tm_map(d.corpus_tag, stripWhitespace) #消除空格
d.corpus_tag <- tm_map(d.corpus_tag, removeNumbers) #移除數字
d.corpus_tag <- tm_map(d.corpus_tag, removePunctuation) #移除標點符號
d.corpus_tag <- tm_map(d.corpus_tag, function(word) { # 移除英數
gsub("[A-Za-z0-9]", "", word)
})
#2. 進行斷詞，並建立文本矩陣 TermDocumentMatrix
seg_tag = lapply(d.corpus_tag, jieba_tokenizer)
tokens_tag = lapply(seg_tag, count_token)
str(tokens_tag)
#TDM
n_tag = length(seg_tag)
TDM_tag = tokens_tag[[1]]
tagNames <- list.files('./data/tang300/by_tag')
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) )
{
TDM_tag = merge(TDM_tag, tokens_tag[[id]], by="d", all = TRUE)
names(TDM_tag) = c('d', tagNames[1:id])
}
TDM_tag[is.na(TDM_tag)] <- 0 #將NA填0
str(TDM_tag)
#3. 將已建好的 TDM 轉成 TF-IDF
tf_tag <- apply(as.matrix(TDM_tag[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idf_tag <- apply(as.matrix(TDM_tag[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
doc.tfidf_tag <- TDM_tag
tempY_tag = matrix(rep(c(as.matrix(tf_tag)), each = length(idf_tag)),
nrow = length(idf_tag))
tempX_tag = matrix(rep(c(as.matrix(idf_tag)), each = length(tf_tag)),
ncol = length(tf_tag), byrow = TRUE)
doc.tfidf_tag[,2:(n+1)] <- (doc.tfidf_tag[,2:(n +1)] / tempY_tag) * tempX_tag
View(doc.tfidf_tag)
###
# EXAMPLE A (唐詩三百首中 各tag詩數量統計) (畫長條圖)
# parameters: None
###
dta$tag
tag_count <- dta$tag %>% strsplit('，') %>% unlist %>% count
tag_count
tag_count = tag_count[rev(order(tag_count$freq)),]
order(tag_count$freq) #小->大
rev(order(tag_count$freq)) #reverse 大->小
tag_count[rev(order(tag_count$freq)),] #用[條件的編號]排序
tag_count = tag_count[tag_count$x %in%  tag_list, ]
ggplot(tag_count, aes(x = reorder(x,-freq), y = freq)) +
geom_bar(stat = "identity", fill='lightblue') +
labs(x='tag',title='唐詩三百首數量統計') +
theme(panel.background = element_blank(),
axis.title = element_text(color = '#2d2d2d'),
axis.text.x = element_text(hjust = 1, size=15),
axis.text.y = element_text(hjust = 1, size=15),
strip.text.x = element_text(color='#2d2d2d',face='bold',size=10),
plot.title = element_text(hjust=0.5,face='bold',size=15))
words_count_tag = TDM_tag[,c('d', input.tag)]
# 選擇tag類別
input.tag = '愛情'
words_count_tag = TDM_tag[,c('d', input.tag)]
words_count_tag
colnames(words_count_tag) = c('word', 'count')
words_count_tag
words_count_tag = words_count_tag[rev(order(words_count_tag$count)),]
str(words_count_tag)
rownames(words_count_tag)=NULL
str(words_count_tag)
words_count_tag
ggplot(words_count_tag[1:20,], aes(x = reorder(word, count), y =count)) +
geom_bar(stat = "identity", fill='lightblue') +
coord_flip()+
labs(x='word', y='count', title=paste('Tag: ', input.tag)) +
theme(panel.background = element_blank(),
axis.title = element_text(color = '#2d2d2d'),
axis.text.x = element_text(hjust = 1, size=15),
axis.text.y = element_text(hjust = 1, size=15),
strip.text.x = element_text(color='#2d2d2d',face='bold',size=10),
plot.title = element_text(hjust=0.5,face='bold',size=15))
str(tfidf)
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf[,2:78]))
head(freq,10)
View(tfidf)
wordfreq= append(tfidf$d, freq)
wordfreq
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
freq
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf[,2:78]))
freq
str(tfidf)
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf[,2:78]))
#找出熱門關鍵詞
freq=rowSums(as.matrix(tfidf[,2:78]))
str(freq)
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
str(freq)
str(as.list(freq))
wordfreq= append(tfidf$d, as.list(freq))
wordfreq
str(wordfreq)
wordfreq= cbind(tfidf$d, as.list(freq))
str(wordfreq)
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
wordfreq= cbind(tfidf$d, as.list(freq))
str(wordfreq)
wordfreq= cbind(tfidf$d, rowSums(tfidf[,2:78]))
str(wordfreq)
wordfreq
tfidf$d
wordfreq= tfidf$d
wordfreq= cbind(wordfreq, freq)
wordfreq
wordfreq= tfidf$d
wordfreq
wordfreq= cbind(wordfreq, freq)
wordfreq
wordfreq= append(wordfreq, freq)
wordfreq
wordfreq= data.frame(tfidf$d, freq)
wordfreq
wordfreq= rev(order(wordfreq$freq))
head(freq,10)
wordfreq
wordfreq= data.frame(tfidf$d, freq)
order(wordfreq$freq)
wordfreq= data.frame(tfidf$d, freq)
wordfreq
wordfreq[order(wordfreq$freq)]
order(wordfreq$freq)
wordfreq[order(wordfreq$freq)]
str(words_count_tag)
str(wordfreq)
wordfreq[order(wordfreq$freq)]
order(wordfreq$freq)
rev(order(wordfreq$freq))
wordfreq[rev(order(wordfreq$freq)))]
wordfreq[rev(order(wordfreq$freq))]
str(wordfreq)
wordfreq
wordfreq[rev(order(wordfreq$freq)),]
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
gsub('\n','',word)})
#斷詞
mixseg = worker()
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
#詞頻向量
count_token = function(d){
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
#詞頻矩陣TDM
n_tag = length(seg)
TDM = tokens[[1]]
tagNames <- list.files('./')
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) ){
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', tagNames[1:id])
}
TDM[is.na(TDM)] <- 0 #將NA填0
#TDM 轉 TF-IDF
tf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
wordfreq= data.frame(tfidf$d, freq)
wordfreq[rev(order(wordfreq$freq)),]
head(wordfreq,10)
tail(wordfreq,10)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
gsub('\n','',word)
gsub(' ','',word)})
#斷詞
mixseg = worker()
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
#詞頻向量
count_token = function(d){
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
#詞頻矩陣TDM
n_tag = length(seg)
TDM = tokens[[1]]
tagNames <- list.files('./')
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) ){
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', tagNames[1:id])
}
TDM[is.na(TDM)] <- 0 #將NA填0
#TDM 轉 TF-IDF
tf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
wordfreq= data.frame(tfidf$d, freq)
wordfreq[rev(order(wordfreq$freq)),]
head(wordfreq,10)
tail(wordfreq,10)
head(wordfreq,10)
View(tfidf)
#建立文本資料結構與基本文字清洗
setwd("D:/CSX_Lyhs/week_5/hw_5/lyrics")
dir = DirSource("./", encoding = "BIG-5")
corpus = Corpus(dir)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
gsub('\n','',word)
gsub(' ','',word)})
#斷詞
mixseg = worker()
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
#詞頻向量
count_token = function(d){
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
#詞頻矩陣TDM
n_tag = length(seg)
TDM = tokens[[1]]
tagNames <- list.files('./')
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) ){
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', tagNames[1:id])
}
TDM[is.na(TDM)] <- 0 #將NA填0
#TDM 轉 TF-IDF
tf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
View(tfidf)
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
wordfreq= data.frame(tfidf$d, freq)
wordfreq[rev(order(wordfreq$freq)),]
#建立文本資料結構與基本文字清洗
setwd("D:/CSX_Lyhs/week_5/hw_5/lyrics")
#建立文本資料結構與基本文字清洗
setwd("D:/CSX_Lyhs/week_5/hw_5/lyrics")
dir = DirSource("./", encoding = "BIG-5")
corpus = Corpus(dir)
length(corpus)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)})
#斷詞
mixseg = worker()
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
str(seg)
#詞頻向量
count_token = function(d){
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
#詞頻矩陣TDM
n_tag = length(seg)
TDM = tokens[[1]]
tagNames <- list.files('./')
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) ){
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', tagNames[1:id])
}
TDM[is.na(TDM)] <- 0 #將NA填0
#TDM 轉 TF-IDF
tf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
View(tfidf)
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
wordfreq= data.frame(tfidf$d, freq)
wordfreq[rev(order(wordfreq$freq)),]
head(wordfreq,10)
str(wordfreq)
order(wordfreq$freq)
wordfreq[order(wordfreq$freq),]
head(wordfreq,10)
wordfreq= wordfreq[rev(order(wordfreq$freq)),]
head(wordfreq,10)
tail(wordfreq,10)
str(TDM)
#找出熱門關鍵詞
freq=rowSums(TDM[,2:78])
wordfreq= data.frame(TDM$d, freq)
wordfreq= wordfreq[rev(order(wordfreq$freq)),]
head(wordfreq,10)
#找出熱門關鍵詞
freq=rowSums(tfidf[,2:78])
wordfreq= data.frame(tfidf$d, freq)
wordfreq= wordfreq[rev(order(wordfreq$freq)),]
head(wordfreq,10)
colnames(wordsfreq) = c('word', 'tfidfsum')
wordfreq= wordfreq[rev(order(wordfreq$freq)),]
colnames(wordfreq) = c('word', 'tfidfsum')
ggplot(wordfreq[1:20,], aes(x = reorder(word, tfidfsum), y =tfidfsum)) +
ggplot(wordfreq[1:20,], aes(x = reorder(word, tfidfsum), y =tfidfsum)) +
geom_bar(stat = "identity", fill='lightblue') +
coord_flip()+
labs(x='word', y='tfidfsum', title= '熱門關鍵詞')+
theme(panel.background = element_blank(),
axis.title = element_text(color = '#2d2d2d'),
axis.text.x = element_text(hjust = 1, size=15),
axis.text.y = element_text(hjust = 1, size=15),
strip.text.x = element_text(color='#2d2d2d',face='bold',size=10),
plot.title = element_text(hjust=0.5,face='bold',size=15))
str(wordfreq)
ggplot(wordfreq[1:20,], aes(x = reorder(word, tfidfsum), y =tfidfsum)) +
geom_bar(stat = "identity", fill='lightblue') +
coord_flip()+
labs(x='word', y='tfidfsum', title= '熱門關鍵詞')+
theme(panel.background = element_blank(),
axis.title = element_text(color = '#2d2d2d'),
axis.text.x = element_text(hjust = 1, size=15),
axis.text.y = element_text(hjust = 1, size=15),
strip.text.x = element_text(color='#2d2d2d',face='bold',size=10),
plot.title = element_text(hjust=0.5,face='bold',size=15))
#Plot those frequencies ordered.
plot(sort(freq, decreasing = T),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
#See the ten most frequent terms.
tail(sort(freq),n=10)
#Plot those frequencies ordered.
plot(sort(wordfreq, decreasing = T),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
#See the ten most frequent terms.
tail(sort(wordfreq),n=10)
#PCA
pca= prcomp(tfidf)
#5. 找前10相似 (input.tag)
rownames(doc.tfidf_tag) = doc.tfidf_tag$d
doc.tfidf_tag <- doc.tfidf_tag[,1:n_tag+1]
#5. 找前10相似 (input.tag)
rownames(tfidf) = tfidf$d
tfidf <- tfidf_tag[,2:78]
#5. 找前10相似 (input.tag)
rownames(tfidf) = tfidf$d
tfidf <- tfidf[,2:78]
cos <- function(x, y){
return (x %*% y / sqrt(x %*% x * y %*% y))[1, 1]
}
input= 漂向北方
docs.cos.sim_tag <- apply(tfidf , 2, cos, y = tfidf[, c(input.tag)])
input= 漂向北方
docs.cos.sim_tag <- apply(tfidf , 2, cos, y = tfidf[, c(input.tag)])
input= '漂向北方'
docs.cos.sim_tag <- apply(tfidf , 2, cos, y = tfidf[, c(input)])
sort(docs.cos.sim_tag, decreasing = TRUE)[1:10]
#6. 唐詩三百首文字雲 (所有tag相加)
#BY tf-idf
f_tag <- sort(rowSums(tfidf), decreasing = T)
docs.df_tag <- data.frame(
word = names(f_tag),
freq = f_tag
)
row.names(docs.df_tag)=NULL
wordcloud(docs.df_tag$word, docs.df_tag$freq, scale=c(3,0.1),max.words=50,
random.order=FALSE, random.color=TRUE,
rot.per=.1, colors=brewer.pal(8,"Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
#PCA
pca= prcomp(tfidf)
g <- ggbiplot(pca, obs.scale = 1, var.scale = 1, ellipse = TRUE, circle = TRUE)
fviz_eig(pca)
fviz_pca_ind(pca, geom= c("point","text","arrow"), col.ind = "cos2")
fviz_pca_var(pca, col.var = "contrib")
#k-means
k_tag = 5
kmeansData_tag = pca$x[,1:2]
cl_tag <- kmeans(kmeansData_tag, k_tag)
kmeansData_tag <- as.data.frame(kmeansData_tag)
kmeansData_tag$cl <- as.factor(cl_tag$cluster)
plot_ly(kmeansData_tag, x= ~PC1, y=~PC2, type='scatter',
mode='text', text=paste0("<b>",rownames(kmeansData_tag),"</b>"),
color = ~cl, colors="Set1", textfont = list(size = 14) )
summary(pca)
#k-means
k_tag = 7
kmeansData_tag = pca$x[,1:2]
cl_tag <- kmeans(kmeansData_tag, k_tag)
kmeansData_tag <- as.data.frame(kmeansData_tag)
kmeansData_tag$cl <- as.factor(cl_tag$cluster)
plot_ly(kmeansData_tag, x= ~PC1, y=~PC2, type='scatter',
mode='text', text=paste0("<b>",rownames(kmeansData_tag),"</b>"),
color = ~cl, colors="Set1", textfont = list(size = 14) )
#k-means
k_tag = 7
kmeansData_tag = pca$x[,1:2]
kmeansData = kmeansData[kmeansData[,1] > -0.05, ]
cl_tag <- kmeans(kmeansData_tag, k_tag)
kmeansData_tag = pca$x[,1:2]
kmeansData_tag = kmeansData_tag[kmeansData_tag[,1] > -0.05, ]
cl_tag <- kmeans(kmeansData_tag, k_tag)
kmeansData_tag <- as.data.frame(kmeansData_tag)
kmeansData_tag$cl <- as.factor(cl_tag$cluster)
plot_ly(kmeansData_tag, x= ~PC1, y=~PC2, type='scatter',
mode='text', text=paste0("<b>",rownames(kmeansData_tag),"</b>"),
color = ~cl, colors="Set1", textfont = list(size = 14) )
kmeansData_tag = pca$x[,1:2]
summary(pca)
str(pca)
View(pca)
k_tag = 5
kmeansData_tag = pcat_tag$x[,1:2]
kmeansData_tag = pcat_tag$x[,1:2]
