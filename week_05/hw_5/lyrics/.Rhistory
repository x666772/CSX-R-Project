new_user_word(mixseg,'想像',"n")
new_user_word(mixseg,'也不',"n")
new_user_word(mixseg,'這是',"n")
new_user_word(mixseg,'再這樣',"n")
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
seg
setwd("D:/CSX_Lyhs/week_6/hw_678/shinylyrics")
##資料前處理
#建立結構與清洗
dir = DirSource("lyrics/", encoding = "BIG-5")
corpus = Corpus(dir)
##資料前處理
#建立結構與清洗
dir = DirSource("lyrics/", encoding = "BIG-5")
corpus = Corpus(dir)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word) })
corpus <- tm_map(corpus, function(word) {
gsub("妳", "你", word) })
#斷詞
mixseg = worker()
new_user_word(mixseg,'為了',"n")
new_user_word(mixseg,'再也',"n")
new_user_word(mixseg,'讓人',"n")
new_user_word(mixseg,'想像',"n")
new_user_word(mixseg,'也不',"n")
new_user_word(mixseg,'這是',"n")
new_user_word(mixseg,'再這樣',"n")
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
seg
setwd("D:/CSX_Lyhs/week_6/hw_678")
##資料前處理
#建立結構與清洗
dir = DirSource("/shinylyrics/lyrics/", encoding = "BIG-5")
##資料前處理
#建立結構與清洗
dir = DirSource("shinylyrics/lyrics/", encoding = "BIG-5")
corpus = Corpus(dir)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word) })
corpus <- tm_map(corpus, function(word) {
gsub("妳", "你", word) })
#斷詞
mixseg = worker()
new_user_word(mixseg,'為了',"n")
new_user_word(mixseg,'再也',"n")
new_user_word(mixseg,'讓人',"n")
new_user_word(mixseg,'想像',"n")
new_user_word(mixseg,'也不',"n")
new_user_word(mixseg,'這是',"n")
new_user_word(mixseg,'再這樣',"n")
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
seg
#-------------------Program---------------------------
# 載入套件包
source('global.R', local = TRUE)
setwd("D:/CSX_Lyhs/week_6/hw_678/shinylyrics")
#-------------------Program---------------------------
# 載入套件包
source('global.R', local = TRUE)
#-------------------Program---------------------------
# 載入套件包
source('global.R', local = TRUE)
##資料前處理
#建立結構與清洗
dir = DirSource("lyrics/", encoding = "BIG-5")
dir
corpus = Corpus(dir)
corpus
corpus[[1]]
#-------------------Program---------------------------
# 載入套件包
source('global.R', local = TRUE)
##資料前處理
#建立結構與清洗
dir = DirSource("lyrics/", encoding = "BIG-5")
corpus = Corpus(dir)
corpus[[1]]
shiny::runApp()
#-------------------Program---------------------------
# 載入套件包
source('global.R', local = TRUE)
##資料前處理
#建立結構與清洗
dir = DirSource("lyrics/", encoding = "BIG-5")
dir
corpus = Corpus(dir)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word) })
corpus <- tm_map(corpus, function(word) {
gsub("妳", "你", word) })
corpus <- tm_map(corpus, function(word) {
gsub("\n", "", word) })
#斷詞
mixseg = worker()
new_user_word(mixseg,'為了',"n")
new_user_word(mixseg,'再也',"n")
new_user_word(mixseg,'讓人',"n")
new_user_word(mixseg,'想像',"n")
new_user_word(mixseg,'也不',"n")
new_user_word(mixseg,'這是',"n")
new_user_word(mixseg,'再這樣',"n")
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
seg
write(seg,'seg.txt')
help(write)
#-------------------Program---------------------------
# 載入套件包
source('global.R', local = TRUE)
install.packages("devtools")
library(devtools)
install_github("bmschmidt/wordVectors")
nearest_to(seg)
install_github("bmschmidt/wordVectors")
nearest_to(seg)
library(wordVectors)
nearest_to(seg)
nearest_to(seg,seg[2])
nearest_to(seg,seg[十年])
##資料前處理
#建立結構與清洗
dir = DirSource("lyrics/", encoding = "BIG-5")
dir
corpus = Corpus(dir)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word) })
corpus <- tm_map(corpus, function(word) {
gsub("妳", "你", word) })
corpus <- tm_map(corpus, function(word) {
gsub("\n", "", word) })
#斷詞
mixseg = worker()
new_user_word(mixseg,'為了',"n")
new_user_word(mixseg,'再也',"n")
new_user_word(mixseg,'讓人',"n")
new_user_word(mixseg,'想像',"n")
new_user_word(mixseg,'也不',"n")
new_user_word(mixseg,'這是',"n")
new_user_word(mixseg,'再這樣',"n")
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
nearest_to(seg,seg[十年])
seg
help("nearest_to")
help("closest_to")
str(seg)
nearest_to(seg,seg[夏天])
nearest_to(seg,seg$`01.txt`)
as.matrix(seg)
help(wordVectors)
??wordVectors
install.packages("tmcn.word2vec", repos="http://R-Forge.R-project.org")
library(tmcn.word2vec)
as.matrix(seg)
as.matrix(unlist(seg))
unlist(seg)
table(unlist(seg))
matrix(unlist(seg))
seg.ma= matrix(unlist(seg))
write(seg.ma)
write(seg.ma,'seg.ma.txt')
TrainingFile2 <- system.file("examples", "seg.ma.txt", package = "tmcn.word2vec")
ModelFile2 <- file.path(tempdir(), "output", "model2.bin")
res2 <- word2vec(TrainingFile2, ModelFile2)
help("system.file")
TrainingFile2 <- system.file("seg.ma.txt", package = "tmcn.word2vec")
ModelFile2 <- file.path(tempdir(), "output", "model2.bin")
res2 <- word2vec(TrainingFile2, ModelFile2)
help("word2vec")
help("train_file")
??train file
??train_file
help("system.file")
TrainingFile2 <- system.file(, "seg.ma.txt", package = "tmcn.word2vec")
#-------------------Program---------------------------
# 載入套件包
source('w2v_global.R', local = TRUE)
install.packages("devtools")
TrainingFile2 <- system.file('examples', "seg.ma.txt", package = "tmcn.word2vec")
ModelFile2 <- file.path(tempdir(), "output", "model2.bin")
res2 <- word2vec(TrainingFile2, ModelFile2)
#-------------------Program---------------------------
# 載入套件包
source('w2v_global.R', local = TRUE)
##資料前處理
#建立結構與清洗
dir = DirSource("lyrics/", encoding = "BIG-5")
dir
corpus = Corpus(dir)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word) })
corpus <- tm_map(corpus, function(word) {
gsub("妳", "你", word) })
corpus <- tm_map(corpus, function(word) {
gsub("\n", "", word) })
#斷詞
mixseg = worker()
new_user_word(mixseg,'為了',"n")
new_user_word(mixseg,'再也',"n")
new_user_word(mixseg,'讓人',"n")
new_user_word(mixseg,'想像',"n")
new_user_word(mixseg,'也不',"n")
new_user_word(mixseg,'這是',"n")
new_user_word(mixseg,'再這樣',"n")
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
str(seg)
seg.ma= matrix(unlist(seg))
TrainingFile2 <- system.file('examples', "seg.ma.txt", package = "tmcn.word2vec")
ModelFile2 <- file.path(tempdir(), "output", "model2.bin")
res2 <- word2vec(TrainingFile2, ModelFile2)
TrainingFile2 <- system.file('./', "seg.ma.txt", package = "tmcn.word2vec")
ModelFile2 <- file.path(tempdir(), "output", "model2.bin")
res2 <- word2vec(TrainingFile2, ModelFile2)
TrainingFile2 <- system.file('', "seg.ma.txt", package = "tmcn.word2vec")
ModelFile2 <- file.path(tempdir(), "output", "model2.bin")
res2 <- word2vec(TrainingFile2, ModelFile2)
TrainingFile2 <- system.file('', "./seg.ma.txt", package = "tmcn.word2vec")
ModelFile2 <- file.path(tempdir(), "output", "model2.bin")
res2 <- word2vec(TrainingFile2, ModelFile2)
#Load required libraries.
library(tm)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(rvest)
library(magrittr)
library(ggplot2)
library(tidytext)
library(stats)
library(proxy)
library(readtext)
library(slam)
library(Matrix)
library(shiny)
library(tidyverse)
library(wordcloud)
library(ggbiplot)
library(factoextra)
library(plotly)
url  <- 'https://mojim.com/twzhot-song.htm'
html <- htmlParse( GET(url) )
xpath= '//*[(@id = "mx5_A") and (((count(preceding-sibling::*) + 1) = 1) and parent::*)]//a[(((count(preceding-sibling::*) + 1) = 1) and parent::*)]'
url.list <- xpathSApply( html, xpath, xmlAttrs )
url.list= url.list[1,]
urls= list()
paster= function(a){paste0('https://mojim.com',a)}
urls= lapply(url.list, paster)
urls= unlist(urls)
tail(urls)
xpath2= '//*[(@id = "fsZx3")]'
xpath3= '//*[(@id = "fsZx2")]'
getdoc <- function(url){
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, xpath2, xmlValue )
title= xpathSApply(html, xpath3, xmlValue)
name <- paste0(title, ".txt")
write(doc, name)
}
#lapply(urls,getdoc)
dir = DirSource("shinylyrics/lyrics", encoding = "BIG-5")
corpus = Corpus(dir)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word) })
corpus <- tm_map(corpus, function(word) {
gsub("妳", "你", word) })
corpus <- tm_map(corpus, function(word) {
gsub("她", "他", word) })
corpus <- tm_map(corpus, function(word) {
gsub("\n", "", word) })
mixseg = worker()
new_user_word(mixseg,c('為了','再也','讓人','想像','也不','這是','再這樣'))
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
count_token = function(d){
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n_tag = length(tokens)
TDM = tokens[[1]]
tagNames=(c('Three Pass(3 pass)','一個人去巴黎','十年','女孩','不染','不僅僅是喜歡','天后','王牌冤家(& ice)','他不懂','以後別做朋友','平凡之路','末班車(Last Train)','目不轉睛','再見煙火','如果雨之後','年少有為','成全','有何不可','但願人長久','你好不好','你要的全拿走','你還要我怎樣','告白氣球','我以為','我在呢','我好想好想你','我們','我們不一樣','戒菸','那些年','那些你很冒險的夢','往後餘生','朋友','南山南','屋頂','星球墜落','洋蔥','修煉愛情','剛好遇見你','浪費','消愁','烏雲中','紙短情長','帶你去旅行','情非得已','涼涼(& 張碧晨)','畢竟深愛過','紳士','雪落下的聲音','魚仔','幾分之幾','斑馬斑馬','最笨的人是我','童話','等你下課 (& 楊瑞代)','答案','想你的夜','愛我別走','愛要怎麼說出口','愛過你這件事','煙火裡的塵埃','落葉歸根','像我這樣的人','漂向北方(& 王力宏)','漂向北方','演員','說謊(FAIRY TALE)','稻香','醉赤壁','學貓叫(& 小潘潘)','擁抱你離去','獨家記憶','輸了你 贏了世界又如何','謝謝妳愛我','離人愁','寶貝兒','讓我留在你身邊'))
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) ){
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', tagNames[1:id])
}
TDM[is.na(TDM)] <- 0 #將NA填0
head(TDM[,2:11])
tf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
head(tfidf[,20:30])
freq=rowSums(tfidf[,2:n_tag+1])
wordfreq= data.frame(tfidf$d, freq)
wordfreq= wordfreq[rev(order(wordfreq$freq)),]
colnames(wordfreq) = c('word', 'tfidfsum')
ggplot(wordfreq[1:10,], aes(x = reorder(word, tfidfsum), y =tfidfsum)) +
geom_bar(stat = "identity", fill='lightblue') +
coord_flip()+
labs(x='word', y='tfidfsum', title= '熱門關鍵詞')+
theme(panel.background = element_blank(),
axis.title = element_text(color = '#2d2d2d'),
axis.text.x = element_text(hjust = 1, size=15),
axis.text.y = element_text(hjust = 1, size=15),
strip.text.x = element_text(color='#2d2d2d',face='bold',size=10),
plot.title = element_text(hjust=0.5,face='bold',size=15))
mixseg = worker()
new_user_word(mixseg,c('為了','再也','讓人','想像','也不','這是','再這樣','為人'))
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
count_token = function(d){
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n_tag = length(tokens)
TDM = tokens[[1]]
tagNames=(c('Three Pass(3 pass)','一個人去巴黎','十年','女孩','不染','不僅僅是喜歡','天后','王牌冤家(& ice)','他不懂','以後別做朋友','平凡之路','末班車(Last Train)','目不轉睛','再見煙火','如果雨之後','年少有為','成全','有何不可','但願人長久','你好不好','你要的全拿走','你還要我怎樣','告白氣球','我以為','我在呢','我好想好想你','我們','我們不一樣','戒菸','那些年','那些你很冒險的夢','往後餘生','朋友','南山南','屋頂','星球墜落','洋蔥','修煉愛情','剛好遇見你','浪費','消愁','烏雲中','紙短情長','帶你去旅行','情非得已','涼涼(& 張碧晨)','畢竟深愛過','紳士','雪落下的聲音','魚仔','幾分之幾','斑馬斑馬','最笨的人是我','童話','等你下課 (& 楊瑞代)','答案','想你的夜','愛我別走','愛要怎麼說出口','愛過你這件事','煙火裡的塵埃','落葉歸根','像我這樣的人','漂向北方(& 王力宏)','漂向北方','演員','說謊(FAIRY TALE)','稻香','醉赤壁','學貓叫(& 小潘潘)','擁抱你離去','獨家記憶','輸了你 贏了世界又如何','謝謝妳愛我','離人愁','寶貝兒','讓我留在你身邊'))
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) ){
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', tagNames[1:id])
}
TDM[is.na(TDM)] <- 0 #將NA填0
head(TDM[,2:11])
tf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
head(tfidf[,20:30])
freq=rowSums(tfidf[,2:n_tag+1])
wordfreq= data.frame(tfidf$d, freq)
wordfreq= wordfreq[rev(order(wordfreq$freq)),]
colnames(wordfreq) = c('word', 'tfidfsum')
ggplot(wordfreq[1:10,], aes(x = reorder(word, tfidfsum), y =tfidfsum)) +
geom_bar(stat = "identity", fill='lightblue') +
coord_flip()+
labs(x='word', y='tfidfsum', title= '熱門關鍵詞')+
theme(panel.background = element_blank(),
axis.title = element_text(color = '#2d2d2d'),
axis.text.x = element_text(hjust = 1, size=15),
axis.text.y = element_text(hjust = 1, size=15),
strip.text.x = element_text(color='#2d2d2d',face='bold',size=10),
plot.title = element_text(hjust=0.5,face='bold',size=15))
mixseg = worker()
new_user_word(mixseg,c('為了','再也','讓人','想像','也不','這是','再這樣','為人','人為'))
jieba_tokenizer = function(d){
unlist(segment(d[[1]], mixseg))
}
seg = lapply(corpus, jieba_tokenizer)
count_token = function(d){
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n_tag = length(tokens)
TDM = tokens[[1]]
tagNames=(c('Three Pass(3 pass)','一個人去巴黎','十年','女孩','不染','不僅僅是喜歡','天后','王牌冤家(& ice)','他不懂','以後別做朋友','平凡之路','末班車(Last Train)','目不轉睛','再見煙火','如果雨之後','年少有為','成全','有何不可','但願人長久','你好不好','你要的全拿走','你還要我怎樣','告白氣球','我以為','我在呢','我好想好想你','我們','我們不一樣','戒菸','那些年','那些你很冒險的夢','往後餘生','朋友','南山南','屋頂','星球墜落','洋蔥','修煉愛情','剛好遇見你','浪費','消愁','烏雲中','紙短情長','帶你去旅行','情非得已','涼涼(& 張碧晨)','畢竟深愛過','紳士','雪落下的聲音','魚仔','幾分之幾','斑馬斑馬','最笨的人是我','童話','等你下課 (& 楊瑞代)','答案','想你的夜','愛我別走','愛要怎麼說出口','愛過你這件事','煙火裡的塵埃','落葉歸根','像我這樣的人','漂向北方(& 王力宏)','漂向北方','演員','說謊(FAIRY TALE)','稻香','醉赤壁','學貓叫(& 小潘潘)','擁抱你離去','獨家記憶','輸了你 贏了世界又如何','謝謝妳愛我','離人愁','寶貝兒','讓我留在你身邊'))
tagNames <- gsub(".txt", "", tagNames) #取代
for( id in c(2:n_tag) ){
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', tagNames[1:id])
}
TDM[is.na(TDM)] <- 0 #將NA填0
head(TDM[,2:11])
tf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 2, sum) #直向相加計算總數
idfCal <- function(word_doc, n){
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n_tag + 1)]), 1, idfCal, n <- n_tag)
tfidf <- TDM
tempY_tag = matrix(rep(c(as.matrix(tf)), each = length(idf)),
nrow = length(idf))
tempX_tag = matrix(rep(c(as.matrix(idf)), each = length(tf)),
ncol = length(tf), byrow = TRUE)
tfidf[,2:(n+1)] <- (tfidf[,2:(n +1)] / tempY_tag) * tempX_tag
head(tfidf[,20:30])
freq=rowSums(tfidf[,2:n_tag+1])
wordfreq= data.frame(tfidf$d, freq)
wordfreq= wordfreq[rev(order(wordfreq$freq)),]
colnames(wordfreq) = c('word', 'tfidfsum')
ggplot(wordfreq[1:10,], aes(x = reorder(word, tfidfsum), y =tfidfsum)) +
geom_bar(stat = "identity", fill='lightblue') +
coord_flip()+
labs(x='word', y='tfidfsum', title= '熱門關鍵詞')+
theme(panel.background = element_blank(),
axis.title = element_text(color = '#2d2d2d'),
axis.text.x = element_text(hjust = 1, size=15),
axis.text.y = element_text(hjust = 1, size=15),
strip.text.x = element_text(color='#2d2d2d',face='bold',size=10),
plot.title = element_text(hjust=0.5,face='bold',size=15))
plot(sort(wordfreq$tfidfsum, decreasing = T),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
rownames(tfidf) = tfidf$d
tfidf <- tfidf[,2:n_tag+1]
f_tag <- sort(rowSums(tfidf), decreasing = T)
docs.df_tag <- data.frame(
word = names(f_tag),
freq = f_tag
)
row.names(docs.df_tag)=NULL
wordcloud(docs.df_tag$word, docs.df_tag$freq, scale=c(3,0.0001),max.words=50,
random.order=FALSE, random.color=TRUE,
rot.per=.1, colors=brewer.pal(8,"Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
cos <- function(x, y){
return (x %*% y / sqrt(x %*% x * y %*% y))[1, 1]
}
input_sim= '一個人去巴黎'
docs.cos.sim_tag <- apply(tfidf , 2, cos, y = tfidf[, c(input_sim)])
names(sort(docs.cos.sim_tag, decreasing = TRUE)[1:10])
pca= prcomp(tfidf)
g <- ggbiplot(pca, obs.scale = 1, var.scale = 1, ellipse = TRUE, circle = TRUE)
fviz_eig(pca)
fviz_pca_ind(pca, geom= c("point","text","arrow"), col.ind = "cos2")
fviz_pca_var(pca, col.var = "contrib")
k_word = 8
kmeansData_word = pca$x[,1:2]
#kmeansData_word = kmeansData_word[kmeansData_word[,1] > -0.05, ]
cl_word <- kmeans(kmeansData_word, k_word)
kmeansData_word <- as.data.frame(kmeansData_word)
kmeansData_word$cl <- as.factor(cl_word$cluster)
plot_ly(kmeansData_word, x= ~PC1, y=~PC2, type='scatter',
mode='text', text=paste0("<b>",rownames(kmeansData_word),"</b>"),
color = ~cl, colors="Set1", textfont = list(size = 14) )
#載入套件包
library(bitops)
library(httr)
library(RCurl)
library(XML)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(rvest)
library(magrittr)
library(ggplot2)
library(tidytext)
library(stats)
library(proxy)
library(readtext)
library(slam)
library(Matrix)
library(dplyr)
#建立文本資料結構與基本文字清洗
setwd("D:/CSX_Lyhs/week_5/hw_5/lyrics")
dir = DirSource("./", encoding = "BIG-5")
dir
corpus = Corpus(dir)
length(corpus)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)})
corpus
unlist(corpus)
text= unlist(corpus)
write(text,'lyrics.txt')
